{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import uuid\n",
    "import json\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Get API key from environment variables\n",
    "api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "api_base = os.getenv(\"DEEPSEEK_API_BASE\", \"https://api.deepseek.com/v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI client with DeepSeek configuration\n",
    "client = OpenAI(\n",
    "    api_key=api_key,\n",
    "    base_url=api_base\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bad_data(json_str):\n",
    "    data = json.loads(json_str)\n",
    "    bad_data = {\n",
    "        \"survey_id\": str(uuid.uuid4()),\n",
    "        \"survey_blob\": \"\"\n",
    "    }\n",
    "    \n",
    "    blobs = []\n",
    "    for q in data['questions']:\n",
    "        blob_parts = [\n",
    "            q.get('question_text', ''),\n",
    "            \"Options: \" + \"; \".join(q.get('answer_options', [])),\n",
    "            \"Routing: \" + q.get('routing_logic', ''),\n",
    "            \"Client Note: \" + q.get('client_notes', ''),\n",
    "            \"Scripter Note: \" + q.get('scripter_notes', ''),\n",
    "            \"Script: \" + json.dumps(q.get('script', {}), ensure_ascii=False)\n",
    "        ]\n",
    "        \n",
    "        # Randomly drop some blob parts (simulate missing info)\n",
    "        blob_parts = [part for part in blob_parts if random.random() > 0.2]\n",
    "\n",
    "        # Randomly shuffle blob parts\n",
    "        random.shuffle(blob_parts)\n",
    "\n",
    "        # Combine parts into a question blob\n",
    "        question_blob = \" | \".join(blob_parts)\n",
    "        blobs.append(question_blob)\n",
    "\n",
    "    # Randomly shuffle questions to remove ordered context\n",
    "    random.shuffle(blobs)\n",
    "\n",
    "    # Combine question blobs into single survey blob\n",
    "    bad_data[\"survey_blob\"] = blobs\n",
    "\n",
    "    return bad_data[\"survey_blob\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.progress import Progress, TimeElapsedColumn, BarColumn, TextColumn, SpinnerColumn\n",
    "from pathlib import Path\n",
    "import json\n",
    "import uuid\n",
    "import logging\n",
    "import time\n",
    "\n",
    "# Configure logging\n",
    "log_path = Path(\"logs\")\n",
    "log_path.mkdir(parents=True, exist_ok=True)\n",
    "logging.basicConfig(\n",
    "    filename=log_path / \"generate_examples.log\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "\n",
    "def generate_examples(prompt_file_path, n_examples=1, model=\"deepseek-reasoner\", temperature=0.7,  \n",
    "                      success_dir=\"data/good\", failed_dir=\"data/good/failed\"):\n",
    "    prompt_path = Path(prompt_file_path)\n",
    "    success_path = Path(success_dir)\n",
    "    failed_path = Path(failed_dir)\n",
    "    success_path.mkdir(parents=True, exist_ok=True)\n",
    "    failed_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    previous_topics = []\n",
    "\n",
    "    with Progress(\n",
    "        SpinnerColumn(),\n",
    "        TextColumn(\"[progress.description]{task.description}\"),\n",
    "        BarColumn(),\n",
    "        TextColumn(\"[progress.percentage]{task.percentage:>3.0f}%\"),\n",
    "        TimeElapsedColumn(),\n",
    "    ) as progress:\n",
    "\n",
    "        overall_task = progress.add_task(\"[green]Generating examples\", total=n_examples)\n",
    "\n",
    "        for i in range(n_examples):\n",
    "            start_time = time.time()\n",
    "\n",
    "            try:\n",
    "                # -----------------------------\n",
    "                # Step 1: Prepare Prompt\n",
    "                # -----------------------------\n",
    "                with open(prompt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    prompt_template = f.read().strip()\n",
    "\n",
    "                exclusion_text = (\n",
    "                    '\\n'.join(f'- \"{topic}\"' for topic in previous_topics)\n",
    "                    if previous_topics else \"\"\n",
    "                )\n",
    "\n",
    "                updated_prompt_content = prompt_template.replace(\n",
    "                    \"<PREVIOUSLY_GENERATED_SURVEY_NAME>\", exclusion_text\n",
    "                ) if previous_topics else prompt_template.replace(\n",
    "                    \"especially the following:\\n- <PREVIOUSLY_GENERATED_SURVEY_NAME>\\n\", \"\"\n",
    "                )\n",
    "\n",
    "                # -----------------------------\n",
    "                # Step 2: API Call\n",
    "                # -----------------------------\n",
    "                response = client.chat.completions.create(\n",
    "                    model=model,\n",
    "                    messages=[{\"role\": \"user\", \"content\": updated_prompt_content}],\n",
    "                    temperature=temperature,\n",
    "                )\n",
    "\n",
    "                # -----------------------------\n",
    "                # Step 3: Clean & Validate JSON\n",
    "                # -----------------------------\n",
    "                response_text = response.choices[0].message.content\n",
    "                cleaned_text = response_text.strip().lstrip(\"```json\").lstrip(\"```\").rstrip(\"```\").strip()\n",
    "\n",
    "                try:\n",
    "                    parsed_data = json.loads(cleaned_text)\n",
    "                    parsed_data['survey_id'] = str(uuid.uuid4())\n",
    "                    cleaned_text = json.dumps(parsed_data, ensure_ascii=False, indent=4)\n",
    "\n",
    "                    new_topic = parsed_data.get('survey_name')\n",
    "                    if new_topic:\n",
    "                        previous_topics.append(new_topic)\n",
    "                        previous_topics = previous_topics[-500:]\n",
    "\n",
    "                    is_valid_json = True\n",
    "\n",
    "                    # Log generated survey topic\n",
    "                    logging.info(f\"Generated Topic #{i+1}: {new_topic}\")\n",
    "\n",
    "                except json.JSONDecodeError as json_err:\n",
    "                    logging.error(f\"[Example #{i+1}] JSON Decode Error: {json_err}\")\n",
    "                    is_valid_json = False\n",
    "\n",
    "                # -----------------------------\n",
    "                # Step 4: Save Survey JSON\n",
    "                # -----------------------------\n",
    "                output_dir = success_path if is_valid_json else failed_path\n",
    "                output_file = output_dir / f\"{parsed_data['survey_id'] if is_valid_json else uuid.uuid4()}.json\"\n",
    "\n",
    "                with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(cleaned_text)\n",
    "\n",
    "                elapsed_time = time.time() - start_time\n",
    "                logging.info(\n",
    "                    f\"[Example #{i+1}] Status: {'valid' if is_valid_json else 'invalid'} - Elapsed: {elapsed_time:.2f}s\"\n",
    "                )\n",
    "\n",
    "                progress.update(\n",
    "                    overall_task, \n",
    "                    advance=1, \n",
    "                    description=f\"[green]Example {i+1}/{n_examples} - Last: {'valid' if is_valid_json else 'invalid'}\"\n",
    "                )\n",
    "\n",
    "            except Exception as e:\n",
    "                elapsed_time = time.time() - start_time\n",
    "                logging.exception(f\"[Example #{i+1}] Unhandled Exception: {e}\")\n",
    "\n",
    "                progress.update(\n",
    "                    overall_task, \n",
    "                    advance=1, \n",
    "                    description=f\"[red]Example {i+1}/{n_examples} - Last: error\"\n",
    "                )\n",
    "\n",
    "    print(\"Generation completed! Logs available at logs/generate_examples.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_examples(\n",
    "    prompt_file_path='prompts/deepseek-good-data.md',\n",
    "    model=\"deepseek-chat\",\n",
    "    n_examples=5, \n",
    "    temperature=1.5\n",
    ")           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_examples(\n",
    "#     prompt_file_path='prompts/deepseek-good-data.md',\n",
    "#     model=\"deepseek-reasoner\",\n",
    "#     n_examples=100, \n",
    "#     temperature=0.7\n",
    "# )              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob\n",
    "\n",
    "# # Create the bad data directory if it doesn't exist\n",
    "# os.makedirs(\"data/bad\", exist_ok=True)\n",
    "\n",
    "# # Iterate over all .jsonl files in the data/good directory\n",
    "# for file_path in glob.glob(\"data/good/*.jsonl\"):\n",
    "#     try:\n",
    "#         # Extract the filename from the path\n",
    "#         filename = os.path.basename(file_path)\n",
    "        \n",
    "#         # Load the good data\n",
    "#         with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "#             good_data = json.load(f)\n",
    "        \n",
    "#         # Generate bad data from the good data\n",
    "#         bad_data = generate_bad_data(json.dumps(good_data, indent=4))\n",
    "        \n",
    "#         # Save the bad data\n",
    "#         output_path = os.path.join(\"data/bad\", filename)\n",
    "#         with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#             json.dump(bad_data, f, ensure_ascii=False)\n",
    "        \n",
    "#         print(f\"Processed {filename}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "# print(\"All files processed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_note_summarizer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
